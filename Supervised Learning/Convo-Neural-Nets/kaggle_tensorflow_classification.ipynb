{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIIHxLVniQMh"
      },
      "outputs": [],
      "source": [
        "#!pip install opendatasets\n",
        "#!pip install pandas\n",
        "import pandas\n",
        "import tensorflow as tf\n",
        "import opendatasets as od"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-v_9OAAirOX"
      },
      "outputs": [],
      "source": [
        "#od.download(\"https://www.kaggle.com/datasets/aryashah2k/indian-medicinal-leaves-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYkA8a7ulznU",
        "outputId": "be58d6a1-a921-4a0d-d316-2868e91a5cd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "DATADIR = \"/content/indian-medicinal-leaves-dataset/Indian Medicinal Leaves Image Datasets/Medicinal plant dataset\"\n",
        "CATEGORIES = [\"Neem\", \"Tulasi\", \"Amla\", \"Castor\", \"Aloevera\", \"Lemon\", \"Jasmine\", \"Insulin\", \"Pepper\", \"Bamboo\", \"Gauva\", \"Henna\", \"Mango\", \"Nagadali\", \"Hibiscus\", \"Honge\", \"Ekka\"]\n",
        "print(len(CATEGORIES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ke5vle0l0aN",
        "outputId": "08279a7c-47eb-406c-bdf6-e6c84f2cb1ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 146/146 [00:00<00:00, 501.66it/s]\n",
            "100%|██████████| 146/146 [00:00<00:00, 677.30it/s]\n",
            "100%|██████████| 146/146 [00:00<00:00, 789.21it/s]\n",
            "100%|██████████| 160/160 [00:00<00:00, 505.55it/s]\n",
            "100%|██████████| 164/164 [00:00<00:00, 590.33it/s]\n",
            "100%|██████████| 146/146 [00:00<00:00, 642.71it/s]\n",
            "100%|██████████| 187/187 [00:00<00:00, 609.63it/s]\n",
            "100%|██████████| 146/146 [00:00<00:00, 566.55it/s]\n",
            "100%|██████████| 146/146 [00:00<00:00, 521.97it/s]\n",
            "100%|██████████| 146/146 [00:00<00:00, 889.70it/s]\n",
            "100%|██████████| 146/146 [00:00<00:00, 734.44it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 594.68it/s]\n",
            "100%|██████████| 146/146 [00:00<00:00, 611.20it/s]\n",
            "100%|██████████| 152/152 [00:00<00:00, 652.85it/s]\n",
            "100%|██████████| 165/165 [00:00<00:00, 378.98it/s]\n",
            "100%|██████████| 146/146 [00:00<00:00, 487.05it/s]\n",
            "100%|██████████| 146/146 [00:00<00:00, 487.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "IMG_SIZE = 256\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:  # do dogs and cats\n",
        "\n",
        "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
        "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
        "\n",
        "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
        "                training_data.append([new_array, class_num])  # add this to our training_data\n",
        "            except Exception as e:  # in the interest in keeping the output clean...\n",
        "                pass\n",
        "            #except OSError as e:\n",
        "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
        "            #except Exception as e:\n",
        "            #    print(\"general exception\", e, os.path.join(path,img))\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "print(len(training_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRVMxHFWl4_D"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.shuffle(training_data)\n",
        "random.shuffle(training_data)\n",
        "random.shuffle(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5f7Zpvnl8Fo"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "for features, label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8llGk-wmBnA"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "X = X / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Hzcs-Vj3By",
        "outputId": "f9f9ddb2-877f-4607-8487-c7bf8a5a2868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "2324/2325 [============================>.] - ETA: 0s - loss: 2.8423 - accuracy: 0.0680"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `Accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with Accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2325/2325 [==============================] - 45s 19ms/step - loss: 2.8423 - accuracy: 0.0680 - val_loss: 2.8344 - val_accuracy: 0.0695\n",
            "Epoch 2/15\n",
            "2324/2325 [============================>.] - ETA: 0s - loss: 2.8341 - accuracy: 0.0706"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `Accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with Accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2325/2325 [==============================] - 43s 19ms/step - loss: 2.8341 - accuracy: 0.0705 - val_loss: 2.8337 - val_accuracy: 0.0695\n",
            "Epoch 3/15\n",
            "2323/2325 [============================>.] - ETA: 0s - loss: 2.8329 - accuracy: 0.0728"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `Accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with Accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2325/2325 [==============================] - 43s 19ms/step - loss: 2.8329 - accuracy: 0.0727 - val_loss: 2.8338 - val_accuracy: 0.0695\n",
            "Epoch 4/15\n",
            "2325/2325 [==============================] - ETA: 0s - loss: 2.8328 - accuracy: 0.0727"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `Accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with Accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2325/2325 [==============================] - 43s 19ms/step - loss: 2.8328 - accuracy: 0.0727 - val_loss: 2.8330 - val_accuracy: 0.0695\n",
            "Epoch 5/15\n",
            "2323/2325 [============================>.] - ETA: 0s - loss: 2.8328 - accuracy: 0.0728"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `Accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with Accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2325/2325 [==============================] - 42s 18ms/step - loss: 2.8328 - accuracy: 0.0727 - val_loss: 2.8337 - val_accuracy: 0.0695\n",
            "Epoch 6/15\n",
            "2325/2325 [==============================] - ETA: 0s - loss: 2.8328 - accuracy: 0.0727"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `Accuracy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with Accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2325/2325 [==============================] - 42s 18ms/step - loss: 2.8328 - accuracy: 0.0727 - val_loss: 2.8333 - val_accuracy: 0.0695\n",
            "Epoch 7/15\n",
            "1259/2325 [===============>..............] - ETA: 18s - loss: 2.8318 - accuracy: 0.0707"
          ]
        }
      ],
      "source": [
        "with tf.device(\"/GPU:0\"):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(256, (3, 3), input_shape = (256, 256, 1)))#X.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(Dense(17))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  model.compile(loss = \"sparse_categorical_crossentropy\",\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])\n",
        "  earlystopping=tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='Accuracy',\n",
        "    min_delta=0.0001,\n",
        "    patience=2,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=5\n",
        "    )\n",
        "\n",
        "  tensorboard= tf.keras.callbacks.TensorBoard()\n",
        "  chkpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    'mango.ckpt',\n",
        "    monitor = 'Accuracy',\n",
        "    save_best_only = True,\n",
        "\n",
        "    mode = 'auto',\n",
        "    save_freq='epoch',\n",
        "    )\n",
        "\n",
        "  model.fit(X, y, batch_size = 1, epochs = 15, validation_split = 0.1, callbacks=[earlystopping,tensorboard,chkpt])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}